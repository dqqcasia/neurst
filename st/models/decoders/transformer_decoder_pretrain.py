'''@file rnn_decoder.py
the while_loop implementation'''

import tensorflow as tf
import logging

from .rna_decoder import RNADecoder
from tensorflow.python.util import nest
from st.models.tools.utils import dense
from st.models.layers import make_multi_cell
from st.layers import common_attention_v1
from st.models.tools.utils import residual, multihead_attention, ff_hidden

inf = 1e10


class Transformer_Decoder_Pretrain(RNADecoder):
    """ctc's `decoder` where the acoustic model is trained with ctc and the distribution
    is shrinked without blank frams. The decoder operates on the shrinked distribution
    which is a sequence labeling problem and the training targets are generated by
    OCD.
    """

    def __init__(self, args, is_train, global_step, embed_table=None, name=None):
        super().__init__(args, is_train, global_step, embed_table, name)
        # use decoder heres
        self.num_blocks = args.model.decoder.num_blocks
        self.num_cell_units = args.model.decoder.num_cell_units
        self.attention_dropout_rate = args.model.decoder.attention_dropout_rate if is_train else 0.0
        self.residual_dropout_rate = args.model.decoder.residual_dropout_rate if is_train else 0.0
        self.num_heads = args.model.decoder.num_heads
        self.size_embedding = args.model.decoder.size_embedding
        self._ff_activation = tf.nn.relu
        self.softmax_temperature = args.model.decoder.softmax_temperature

    def decode(self, encoded, len_encoded, decoder_input):
        """
        used for MLE training
        """
        decoder_output = self.decoder_impl(decoder_input, encoded, len_encoded)

        logits = tf.layers.dense(
            decoder_output,
            self.args.dim_output,
            use_bias=False,
            name='decoder_fc')

        preds = tf.to_int32(tf.argmax(logits, axis=-1))

        return logits, preds, len_encoded

    def decoder_with_caching(self, encoded, len_encoded):
        """
        gread search, used for OCD training or infer
        """
        batch_size = tf.shape(encoded)[0]
        token_init = tf.fill([batch_size, 1], self.start_token)
        logits_init = tf.zeros([batch_size, 1, self.dim_output], dtype=tf.float32)
        finished_init = tf.zeros([batch_size], dtype=tf.bool)
        len_decoded_init = tf.ones([batch_size], dtype=tf.int32)
        cache_decoder_init = tf.zeros([batch_size, 0, self.num_blocks, self.num_cell_units])
        encoder_padding = tf.equal(tf.sequence_mask(len_encoded, maxlen=tf.shape(encoded)[1]), False) # bool tensor
        encoder_attention_bias = common_attention_v1.attention_bias_ignore_padding(encoder_padding)

        def step(i, preds, cache_decoder, logits, len_decoded, finished):

            preds_emb = self.embedding(preds)
            decoder_input = preds_emb

            decoder_output, cache_decoder = self.decoder_with_caching_impl(
                decoder_input,
                cache_decoder,
                encoded,
                encoder_attention_bias)

            cur_logit = tf.layers.dense(
                inputs=decoder_output[:, -1, :],
                units=self.dim_output,
                activation=None,
                use_bias=False,
                name='decoder_fc')

            cur_ids = tf.to_int32(tf.argmax(cur_logit, -1))
            preds = tf.concat([preds, cur_ids[:, None]], axis=1)
            logits = tf.concat([logits, cur_logit[:, None]], 1)

            # Whether sequences finished.
            has_eos = tf.equal(cur_ids, self.end_token)
            finished = tf.logical_or(finished, has_eos)
            len_decoded += 1-tf.to_int32(finished)


            return i+1, preds, cache_decoder, logits, len_decoded, finished

        def not_finished(i, preds, cache, logit, len_decoded, finished):
            return tf.logical_and(
                tf.reduce_any(tf.logical_not(finished)),
                tf.less(
                    i,
                    tf.reduce_min([tf.shape(encoded)[1] + 50, self.args.max_len])  # maxlen = 100
                )
            )

        i, preds, cache_decoder, logits, len_decoded, finished = tf.while_loop(
            cond=not_finished,
            body=step,
            loop_vars=[0, token_init, cache_decoder_init, logits_init, len_decoded_init, finished_init],
            shape_invariants=[tf.TensorShape([]),
                              tf.TensorShape([None, None]),
                              tf.TensorShape([None, None, None, None]),
                              tf.TensorShape([None, None, self.dim_output]),
                              tf.TensorShape([None]),
                              tf.TensorShape([None])]
            )
        len_decoded -= 1-tf.to_int32(finished)  # for decoded length cut by encoded length
        logits = logits[:, 1:, :]
        preds = preds[:, 1:]
        not_padding = tf.to_int32(tf.sequence_mask(len_decoded))
        preds = tf.multiply(tf.to_int32(preds), not_padding)

        return logits, preds, len_decoded

    def decoder_with_caching_impl(self, decoder_input, decoder_cache, encoder_output, encoder_attention_bias):
        # Positional Encoding
        decoder_input += common_attention_v1.add_timing_signal_1d(decoder_input)
        # Dropout
        decoder_output = tf.layers.dropout(decoder_input,
                                           rate=self.residual_dropout_rate,
                                           training=self.is_train)
        new_cache = []

        # rest block with residual
        for i in range(self.num_blocks):
            with tf.variable_scope("block_{}".format(i)):
                # Multihead Attention (self-attention)
                # the caching_impl only need to calculate decoder_output[:, -1:, :]!
                decoder_output = residual(decoder_output[:, -1:, :],
                                          multihead_attention(
                                              query_antecedent=decoder_output,
                                              memory_antecedent=None,
                                              bias=None,
                                              total_key_depth=self.num_cell_units,
                                              total_value_depth=self.num_cell_units,
                                              num_heads=self.num_heads,
                                              dropout_rate=self.attention_dropout_rate,
                                              num_queries=1,
                                              output_depth=self.num_cell_units,
                                              name="decoder_self_attention",
                                              summaries=False),
                                          dropout_rate=self.residual_dropout_rate)

                # Multihead Attention (vanilla attention)
                decoder_output = residual(decoder_output,
                                          multihead_attention(
                                              query_antecedent=decoder_output,
                                              memory_antecedent=encoder_output,
                                              bias=encoder_attention_bias,
                                              total_key_depth=self.num_cell_units,
                                              total_value_depth=self.num_cell_units,
                                              output_depth=self.num_cell_units,
                                              num_heads=self.num_heads,
                                              dropout_rate=self.attention_dropout_rate,
                                              num_queries=1,
                                              name="decoder_vanilla_attention",
                                              summaries=False),
                                          dropout_rate=self.residual_dropout_rate)

                # Feed Forward
                decoder_output = residual(decoder_output,
                                          ff_hidden(
                                              decoder_output,
                                              hidden_size=4 * self.num_cell_units,
                                              output_size=self.num_cell_units,
                                              activation=tf.nn.relu),
                                          dropout_rate=self.residual_dropout_rate)

                decoder_output = tf.concat([decoder_cache[:, :, i, :], decoder_output], axis=1)
                new_cache.append(decoder_output[:, :, None, :])

        new_cache = tf.concat(new_cache, axis=2)

        return decoder_output, new_cache

    def decoder_impl(self, decoder_input, encoder_output, len_encoded):

        encoder_padding = tf.equal(tf.sequence_mask(len_encoded, maxlen=tf.shape(encoder_output)[1]), False)

        encoder_attention_bias = common_attention_v1.attention_bias_ignore_padding(encoder_padding)


        decoder_output = self.embedding(decoder_input)
        # Positional Encoding
        decoder_output += common_attention_v1.add_timing_signal_1d(decoder_output)
        # Dropout
        decoder_output = tf.layers.dropout(decoder_output,
                                           rate=self.residual_dropout_rate,
                                           training=self.is_train)
        # Bias for preventing peeping later information
        self_attention_bias = common_attention_v1.attention_bias_lower_triangle(tf.shape(decoder_input)[1])

        # Blocks
        for i in range(self.num_blocks):
            with tf.variable_scope("block_{}".format(i)):
                # Multihead Attention (self-attention)
                decoder_output = residual(decoder_output,
                                          multihead_attention(
                                              query_antecedent=decoder_output,
                                              memory_antecedent=None,
                                              bias=self_attention_bias,
                                              total_key_depth=self.num_cell_units,
                                              total_value_depth=self.num_cell_units,
                                              num_heads=self.num_heads,
                                              dropout_rate=self.attention_dropout_rate,
                                              output_depth=self.num_cell_units,
                                              name="decoder_self_attention",
                                              summaries=True),
                                          dropout_rate=self.residual_dropout_rate)

                # Multihead Attention (vanilla attention)
                decoder_output = residual(decoder_output,
                                          multihead_attention(
                                              query_antecedent=decoder_output,
                                              memory_antecedent=encoder_output,
                                              bias=encoder_attention_bias,
                                              # bias=None,
                                              total_key_depth=self.num_cell_units,
                                              total_value_depth=self.num_cell_units,
                                              output_depth=self.num_cell_units,
                                              num_heads=self.num_heads,
                                              dropout_rate=self.attention_dropout_rate,
                                              name="decoder_vanilla_attention",
                                              summaries=True),
                                          dropout_rate=self.residual_dropout_rate)

                # Feed Forward
                decoder_output = residual(decoder_output,
                                          ff_hidden(
                                              decoder_output,
                                              hidden_size=4 * self.num_cell_units,
                                              output_size=self.num_cell_units,
                                              activation=self._ff_activation),
                                          dropout_rate=self.residual_dropout_rate)

        return decoder_output

    def beam_decode_rerank(self, encoded, len_encoded):
        """
        beam search rerank at end with language model integration (self-attention model)
        the input to te score is <sos> + tokens !!!
        """
        lambda_lm = self.args.lambda_lm
        beam_size = self.beam_size
        batch_size = tf.shape(len_encoded)[0]

        encoded = tf.tile(encoded[:, None, :, :],
                          multiples=[1, beam_size, 1, 1])
        encoded = tf.reshape(encoded,
                             [batch_size * beam_size, -1, encoded.get_shape()[-1].value])
        len_encoded = tf.reshape(tf.tile(len_encoded[:, None], multiples=[1, beam_size]), [-1])

        token_init = tf.fill([batch_size * beam_size, 1], self.args.sos_idx)
        logits_init = tf.zeros([batch_size * beam_size, 1, self.dim_output], dtype=tf.float32)
        len_decoded_init = tf.ones_like(len_encoded, dtype=tf.int32)
        scores = tf.constant([0.0] + [-inf] * (beam_size - 1), dtype=tf.float32)
        scores = tf.tile(scores, multiples=[batch_size])
        finished_init = tf.zeros_like(scores, dtype=tf.bool)

        cache_decoder_init = tf.zeros([batch_size * beam_size,
                                       0,
                                       self.num_blocks,
                                       self.num_cell_units])

        cache_init = 0

        base_indices = tf.reshape(tf.tile(tf.range(batch_size)[:, None], multiples=[1, beam_size]), shape=[-1])

        encoder_padding = tf.equal(tf.sequence_mask(len_encoded, maxlen=tf.shape(encoded)[1]), False)
        encoder_attention_bias = common_attention_v1.attention_bias_ignore_padding(encoder_padding)

        def step(i, preds, scores, cache_decoder, cache_lm, logits, len_decoded, finished):
            """
            the cache has no specific shape, so no can be put in the all_states
            """
            preds_emb = self.embedding(preds)
            decoder_input = preds_emb

            decoder_output, cache_decoder = self.decoder_with_caching_impl(
                decoder_input,
                cache_decoder,
                encoded,
                encoder_attention_bias)

            cur_logit = tf.layers.dense(
                inputs=decoder_output[:, -1, :],
                units=self.dim_output,
                activation=None,
                use_bias=False,
                name='decoder_fc')

            logits = tf.concat([logits, cur_logit[:, None]], 1)
            z = tf.nn.log_softmax(cur_logit)


            z_lm = tf.zeros_like(z)

            def get_bias_scores(scores, bias):
                """
                If a sequence is finished, we only allow one alive branch. This function aims to give one branch a zero score
                and the rest -inf score.
                Args:
                    scores: A real value array with shape [batch_size * beam_size, beam_size].
                    bias: A bool array with shape [batch_size * beam_size].

                Returns:
                    A real value array with shape [batch_size * beam_size, beam_size].
                """
                bias = tf.to_float(bias)
                b = tf.constant([0.0] + [-inf] * (beam_size - 1))
                b = tf.tile(b[None, :], multiples=[batch_size * beam_size, 1])
                return scores * (1 - bias[:, None]) + b * bias[:, None]

            def get_bias_preds(preds, bias):
                """
                If a sequence is finished, all of its branch should be </S> (3).
                Args:
                    preds: A int array with shape [batch_size * beam_size, beam_size].
                    bias: A bool array with shape [batch_size * beam_size].

                Returns:
                    A int array with shape [batch_size * beam_size].
                """
                bias = tf.to_int32(bias)
                return preds * (1 - bias[:, None]) + bias[:, None] * self.end_token

            # rank the combined scores
            next_scores, next_preds = tf.nn.top_k(z+z_lm, k=beam_size, sorted=True)
            next_preds = tf.to_int32(next_preds)

            next_preds = get_bias_preds(next_preds, finished)
            next_scores = get_bias_scores(next_scores, finished)

            # beamed scores & Pruning
            scores = scores[:, None] + next_scores
            scores = tf.reshape(scores, shape=[batch_size, beam_size * beam_size])

            # LP scores.
            len_decoded = len_decoded[:, None] + tf.to_int32(tf.not_equal(next_preds, self.end_token))
            len_decoded = tf.reshape(len_decoded, shape=[batch_size, beam_size ** 2])
            lp = tf.pow((5 + len_decoded) / (5 + 1), self.args.length_penalty_weight)
            lp_scores = scores / tf.cast(lp, dtype=tf.float32)
            scores = lp_scores

            _, k_indices = tf.nn.top_k(scores, k=beam_size)
            k_indices = base_indices * beam_size * beam_size + tf.reshape(k_indices, shape=[-1])

            # Update lengths.
            len_decoded = tf.gather(tf.reshape(len_decoded, shape=[-1]), indices=k_indices)

            # Update scores.
            scores = tf.gather(tf.reshape(scores, shape=[-1]), indices=k_indices)

            # Update predictions.
            next_preds = tf.gather(tf.reshape(next_preds, shape=[-1]), indices=k_indices)

            # k_indices: [0~batch*beam*beam], preds: [0~batch*beam]
            preds = tf.gather(preds, indices=k_indices // beam_size)
            cache_decoder = tf.gather(cache_decoder, indices=tf.cast(k_indices / beam_size, dtype=tf.int64))

            preds = tf.concat((preds, next_preds[:, None]), axis=1)

            has_eos = tf.equal(next_preds, self.end_token)
            finished = tf.logical_or(finished, has_eos)

            return i+1, preds, scores, cache_decoder, cache_lm, logits, len_decoded, finished

        def not_finished(i, preds, scores, cache_decoder, cache_lm, logit, len_decoded, finished):
            return tf.logical_and(
                tf.reduce_any(tf.logical_not(finished)),
                tf.less(
                    i,
                    tf.reduce_min([tf.shape(encoded)[1] + 50, self.args.max_len])
                )
            )

        _, preds, scores_am, _, _, logits, len_decoded, finished = tf.while_loop(
            cond=not_finished,
            body=step,
            loop_vars=[0, token_init, scores, cache_decoder_init, cache_init, logits_init, len_decoded_init, finished_init],
            shape_invariants=[tf.TensorShape([]),
                              tf.TensorShape([None, None]),
                              tf.TensorShape([None]),
                              tf.TensorShape([None, None, None, None]),
                              tf.TensorShape([]),
                              tf.TensorShape([None, None, self.dim_output]),
                              tf.TensorShape([None]),
                              tf.TensorShape([None])]
            )

        len_decoded -= 1-tf.to_int32(finished)
        preds = preds[:, 1:]
        logits = logits[:, 1:, :]
        scores_lm = 0
        scores = scores_am + scores_lm
        scores_sorted, sorted = tf.nn.top_k(tf.reshape(scores, [batch_size, beam_size]),
                                            k=beam_size,
                                            sorted=True)

        sorted = base_indices * beam_size + tf.reshape(sorted, shape=[-1])

        logits_sorted = tf.gather(logits, sorted)
        preds_sorted = tf.gather(preds, sorted)
        scores_am_sorted = tf.gather(scores_am, sorted)
        scores_lm_sorted = scores_am_sorted

        scores_lm_sorted = tf.reshape(scores_lm_sorted, shape=[batch_size, beam_size])
        scores_am_sorted = tf.reshape(scores_am_sorted, shape=[batch_size, beam_size])
        preds_sorted = tf.reshape(preds_sorted, shape=[batch_size, beam_size, -1])
        return [preds_sorted, scores_am_sorted, scores_lm_sorted], preds_sorted[:, 0, :], len_decoded

    def forward(self, i, preds, state_decoder):
        """
        self.cell
        self.encoded
        """
        prev_emb = self.embedding(preds[:, -1])
        decoder_input = tf.concat([self.encoded[:, i, :], prev_emb], axis=1)
        decoder_input.set_shape([None, self.num_cell_units_en+self.size_embedding])

        with tf.variable_scope(self.name or 'decoder', reuse=True):
            with tf.variable_scope("decoder_lstms"):
                output_decoder, state_decoder = tf.contrib.legacy_seq2seq.rnn_decoder(
                    decoder_inputs=[decoder_input],
                    initial_state=state_decoder,
                    cell=self.cell)

            cur_logit = tf.layers.dense(
                inputs=output_decoder[0],
                units=self.dim_output,
                activation=None,
                use_bias=False,
                name='fully_connected'
                )
            cur_ids = tf.to_int32(tf.argmax(cur_logit, -1))

        return cur_ids, state_decoder
